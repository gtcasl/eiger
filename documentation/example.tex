\section{Example}
\label{sec:example}

In this section we will walk through the entire pipeline of data acquisition, model generation, model analysis, and output. Included in the \texttt{experiment/} directory are:
	\begin{itemize}
	\item A small matrix multiplication application already annotated with the C++ API.
	\item Golden reference versions of all the models created in this tutorial.
	\item A dump of the database containing all measurements used to create the reference models.
	\end{itemize}
	We will use this as the sandbox to demonstrate Eiger's functionality.

\subsection{Getting Started}
The process by which models are created works as follows:
	\begin{enumerate}
	\item Data is collected and stored in Eiger.
	\item Models are generated.
	\item Models are analyzed.
	\item Models are output in a final format.
	\end{enumerate}
This exmple will walk through each of these steps. Before beginning, the C++ API, modeling framework, and internal database have to be set up. For instructions on how to do this, see the \texttt{README}.

A database file containing this example data is provided.

\subsection{The Application}
The application we will be modeling is a very simple matrix-matrix multiplication, where each matrix is square. Progressively larger matrices are multiplied together and timed, the presumption being that the size of these matrices will be a good indicator for the performance of the matrix multiplication kernel. The included code is already annotated with the appropriate Eiger API calls so that the data can be sent to the internal Eiger data store. 

To begin, the execution environment is set up. The Eiger database is connected to, the specifics of the machine, application, and workload are established. In this example, there are only two \texttt{Metric}s: the size of the input matrix(i.e. number of rows and columns), and the execution time per data point. Each iteration of the outer loop then marks a new \texttt{Trial} and \texttt{Execution}, as well as marking down the values for the individual \texttt{Metric}s. Clean up at the end disconnects from the Eiger internal data store.

It is important to note that each object needs to be send to the database, performed by the \texttt{commit()} member functions. This flushes the data to the database so that it can be used for modeling.

Compiling the application requires indicating the location of the C++ API include directory, typically \texttt{/usr/local/include/eiger}, and the API library, e.g.
	\begin{quote}
	\texttt{g++ -I/usr/local/include/eiger matmul.cc -o matmul -leigerInterface}
	\end{quote}

Run the application like this:
	\begin{quote}
	\texttt{./matmul}
	\end{quote}
It will ask you for the information necessary to connect to the Eiger database.

\subsection{Modeling}
All the modeling functionality is built into the \texttt{Eiger.py} script. All the options and their descriptions can be found by issuing the following command: 
	\begin{quote}
	\texttt{Eiger.py -h}
	\end{quote}

Since the data for the models resides in the database, the connection flag is required:
	\begin{description}
	\item[\texttt{--db}] Name of the database.
	\end{description}
Making models requires the name of the \texttt{DataCollection} and the metric to predict. Here's how you make a basic model:
	\begin{quote}
	\texttt{Eiger.py --db test.db -t example --performance-metric runtime}
	\end{quote}

Most analytics require an experiment to be run, as they demonstrate how well the model performs. There are two ways to explore the quality of the model produced: how closely it fits to the training data, and how well it extrapolates to unseen data.

To explore how well the model fits the training data, and to allow us to play around with some settings, set fit test and turn on the statistics:
	\begin{quote}
	\texttt{Eiger.py --db test.db -t example --performance-metric runtime
                     --test-fit --show-prediction-statistics}
	\end{quote}
This will print out some statistics about how well the trained model fits to the training data. The golden version of this model is in the \texttt{gold.model} file.

Let's turn on some analysis figures to explore the quality of the program. Most plotting functions pertain to the principal component analysis; while PCA is performed in this example, there is only one training variable (the size of the model), which will result in only one principal component identical to this variable. Let's turn on a scatter plot of predicted versus actual performance:
	\begin{quote}
	\texttt{Eiger.py --db test.db -t example --performance-metric runtime
                     --test-fit --show-prediction-statistics
                     --plot-performance-scatter}
	\end{quote}

One important setting that affects the quality of the model is the {\em threshold}. This determines how much additional benefit an added term to the model must have to be retained. Compare difference in root mean squared error when the threshold goes from 0.01:
	\begin{quote}
	\texttt{Eiger.py --db test.db -t example --performance-metric runtime
                     --test-fit --show-prediction-statistics
                     --plot-performance-scatter
                     --threshold 0.01}
	\end{quote}
up to 0.1:
	\begin{quote}
	\texttt{Eiger.py --db test.db -t example --performance-metric runtime
                     --test-fit --show-prediction-statistics
                     --plot-performance-scatter
                     --threshold 0.1}
	\end{quote}
The golden model files for these models are \texttt{gold-threshold-0.01.model} and \texttt{gold-threshold-0.1.model}, respectively. For more information on threshold, see the Eiger WPEA12 paper, included in the \texttt{documentation} directory.

There are many more flags for specifying subsets of \texttt{DataCollections} to use, how to vary principal components, as well as many more plotting functions. Please see the Eiger help command for more details:
	\begin{quote}
	\texttt{Eiger.py -h}
	\end{quote}

\subsection{Saving Models}
Models are only saved by using the {\em output} flag to Eiger, like so:
	\begin{quote}
	\texttt{Eiger.py OTHER\_FLAGS -o}
	\end{quote}
Here the model, which is constructed under the constraints in the other flags (not shown), is output into a file with a name of the format \texttt{DATACOLLECTION.model}. This file is a human-readable text file. In general, it contains the principal component analysis rotation matrix, the model functions, their weights, and the names of the metrics that this model requires. For more details on the file format of the models, see Section \ref{sec:modelfile}.

